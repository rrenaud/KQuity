{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d387e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56051c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base = 'gameevents_0[0-7][0-9].csv'\n",
    "test_base = 'gameevents_0[8-9][0-9].csv'\n",
    "expt_suffix = 'gold_symmetry_no_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72c1cdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vectors(pattern):\n",
    "    X = np.load(f'{pattern}_{expt_suffix}_states.npy')\n",
    "    y = np.load(f'{pattern}_{expt_suffix}_labels.npy')\n",
    "    return X, y\n",
    "\n",
    "train_X, train_y = load_vectors(train_base)\n",
    "test_X, test_y = load_vectors(test_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ac70f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(t_y, num_leaves, objective='binary'):\n",
    "    train_data = lgb.Dataset(train_X, t_y)\n",
    "    param = {'num_leaves': num_leaves, 'objective': objective, 'metric': 'binary_logloss', 'boosting': 'gbdt'}\n",
    "    return lgb.train(param, train_data, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4934460f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 433643, number of negative: 441060\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 486\n",
      "[LightGBM] [Info] Number of data points in the train set: 874703, number of used features: 76\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495760 -> initscore=-0.016959\n",
      "[LightGBM] [Info] Start training from score -0.016959\n"
     ]
    }
   ],
   "source": [
    "bst = train(train_y, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f7adfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_train_y = bst.predict(train_X)\n",
    "#def avg(l):\n",
    "#    return sum(l)/len(l)\n",
    "\n",
    "#print(avg(train_y), avg(new_train_y))\n",
    "#print(avg([new_y for old_y, new_y in zip(train_y, new_train_y) if old_y == 0]))\n",
    "#print(avg([new_y for old_y, new_y in zip(train_y, new_train_y) if old_y == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bad07fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.70      0.69    629982\n",
      "           1       0.69      0.66      0.67    622564\n",
      "\n",
      "    accuracy                           0.68   1252546\n",
      "   macro avg       0.68      0.68      0.68   1252546\n",
      "weighted avg       0.68      0.68      0.68   1252546\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(test_y, bst.predict(test_X) > .5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffe926b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_preds = bst.predict(test_X)\n",
    "#bst2_preds = bst2.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b45f1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(expt_suffix + '_preds.npy', bst_preds)\n",
    "# np.save(expt_suffix + '_preds2.npy', bst2_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f04c89",
   "metadata": {},
   "source": [
    "\n",
    "# gold symettry - 0.5824847835677649\n",
    "# gold symettry no id - 0.5821129501048026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1751d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5821129501048026\n"
     ]
    }
   ],
   "source": [
    "ll1 = sklearn.metrics.log_loss(test_y, bst_preds)\n",
    "#ll2 = sklearn.metrics.log_loss(test_y, bst2_preds)\n",
    "\n",
    "print(ll1)\n",
    "#print(ll2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb7f051e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000013"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "sklearn.metrics.log_loss(test_y, np.ones_like(test_y) * .5) / math.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8787b74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_diff_preds = np.load('no_team_diff__preds.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a6809d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5830473591163567"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.log_loss(test_y, no_diff_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7443af15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "def iterate_unseen_states():\n",
    "    csv_path = 'validated_all_gameevent_partitioned/gameevents_0[8-9][0-9].csv'\n",
    "\n",
    "    events = iterate_events_from_csv(csv_path)\n",
    "    map_structure_infos = map_structure.MapStructureInfos()\n",
    "\n",
    "    yield from iterate_game_events_with_state(events, map_structure_infos)\n",
    "\n",
    "def compute_seq():\n",
    "    count = 0\n",
    "\n",
    "    for game_id, event, game_state, all_game_events in iterate_unseen_states():\n",
    "        if game_state.get_team(Team.BLUE).eggs != 2:\n",
    "            if (count % 100 == 0):\n",
    "                print(count)\n",
    "            count += 1\n",
    "            if count > 1000:\n",
    "                break\n",
    "            new_gs = copy.deepcopy(game_state)\n",
    "            \n",
    "            new_gs.get_team(Team.BLUE).eggs += 1\n",
    "            new_encoded = vectorize_game_state(new_gs, event)\n",
    "            old_encoded = vectorize_game_state(game_state, event)\n",
    "            preds = bst.predict([old_encoded, new_encoded])\n",
    "            pred_diff = preds[1] - preds[0]\n",
    "            yield(pred_diff)\n",
    "\n",
    "deltas = list(compute_seq())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65e413a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "991"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(d >= 0 for d in deltas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
